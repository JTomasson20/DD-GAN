{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c80aca4",
   "metadata": {},
   "source": [
    "# Example usage notebook of the DD-GAN repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125a501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db5d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb90e81",
   "metadata": {},
   "source": [
    "After installation of the ddgan package run the following line to import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a5d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ddgan\n",
    "from ddgan import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c74fa",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6876d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPOD = 5\n",
    "evaluated_subdomains = 2\n",
    "subdomains = 4\n",
    "start_from = 400\n",
    "steps = 10\n",
    "dims = 3\n",
    "datapoints = 1000 + steps - 1\n",
    "\n",
    "\n",
    "csv_data = np.load('../data/processed/pod_coeffs_field_Velocity.npy', )\n",
    "\n",
    "assert nPOD <= csv_data.shape[1], \"Make sure the data includes enough POD coeffs\"\n",
    "assert datapoints + start_from <= csv_data.shape[2], \"Not enough data\"\n",
    "assert evaluated_subdomains + 2 <= csv_data.shape[0], \"Not enough domains\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82392a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 1009)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cutting the dataset\n",
    "csv_data = csv_data[:subdomains,:nPOD,start_from:start_from+datapoints]\n",
    "csv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7937c636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1009, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transposing data\n",
    "tmp_data = np.ones([subdomains, datapoints, nPOD])\n",
    "\n",
    "new_data = np.ones([subdomains, nPOD, datapoints])\n",
    "for i in range(subdomains):\n",
    "    for j in range(nPOD):\n",
    "        for k in range(datapoints):\n",
    "            new_data[i][j][k] = nPOD*j + (i + 1)*10000 + k  \n",
    "\n",
    "for k in range(subdomains):\n",
    "    #tmp_data[k] = csv_data[k].T\n",
    "    tmp_data[k] = new_data[k].T\n",
    "    \n",
    "csv_data = tmp_data\n",
    "csv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba4b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scales = []\n",
    "csv_data2 = np.zeros_like(csv_data)\n",
    "for i in range(subdomains):\n",
    "    scales.append(sklearn.preprocessing.MinMaxScaler(feature_range=[-1,1]))\n",
    "    csv_data2[i] = scales[i].fit_transform(csv_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a610f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asserting scaling is accurate\n",
    "cond = np.zeros_like(csv_data2)\n",
    "for i in range(subdomains):\n",
    "    cond[i] = scales[i].inverse_transform(csv_data2[i])\n",
    "assert np.allclose(csv_data[0,:,0], cond[0,:,0]), \"Scaling failed\"  \n",
    "\n",
    "for dim in range(subdomains):\n",
    "    for icol in range(nPOD):\n",
    "        assert np.isclose(np.min(csv_data2[dim][:,icol]) + np.max(csv_data2[dim][:,icol]), 0), \"Scaling failed\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36fa044b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10000., 10005., 10010., 10015., 10020.],\n",
       "        [10001., 10006., 10011., 10016., 10021.],\n",
       "        [10002., 10007., 10012., 10017., 10022.],\n",
       "        ...,\n",
       "        [11006., 11011., 11016., 11021., 11026.],\n",
       "        [11007., 11012., 11017., 11022., 11027.],\n",
       "        [11008., 11013., 11018., 11023., 11028.]],\n",
       "\n",
       "       [[20000., 20005., 20010., 20015., 20020.],\n",
       "        [20001., 20006., 20011., 20016., 20021.],\n",
       "        [20002., 20007., 20012., 20017., 20022.],\n",
       "        ...,\n",
       "        [21006., 21011., 21016., 21021., 21026.],\n",
       "        [21007., 21012., 21017., 21022., 21027.],\n",
       "        [21008., 21013., 21018., 21023., 21028.]],\n",
       "\n",
       "       [[30000., 30005., 30010., 30015., 30020.],\n",
       "        [30001., 30006., 30011., 30016., 30021.],\n",
       "        [30002., 30007., 30012., 30017., 30022.],\n",
       "        ...,\n",
       "        [31006., 31011., 31016., 31021., 31026.],\n",
       "        [31007., 31012., 31017., 31022., 31027.],\n",
       "        [31008., 31013., 31018., 31023., 31028.]],\n",
       "\n",
       "       [[40000., 40005., 40010., 40015., 40020.],\n",
       "        [40001., 40006., 40011., 40016., 40021.],\n",
       "        [40002., 40007., 40012., 40017., 40022.],\n",
       "        ...,\n",
       "        [41006., 41011., 41016., 41021., 41026.],\n",
       "        [41007., 41012., 41017., 41022., 41027.],\n",
       "        [41008., 41013., 41018., 41023., 41028.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a6ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = np.ones([subdomains, nPOD, datapoints])\n",
    "# for i in range(subdomains):\n",
    "#     for j in range(nPOD):\n",
    "#             new_data[i][j] = nPOD*j + i  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ca83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the data into subdomains \n",
    "# 2 x nTrain x nsteps * nPOD *3 # 'float32' or np.float32\n",
    "t_begin = 0\n",
    "t_end = datapoints-steps + 1\n",
    "\n",
    "training_data = np.zeros((evaluated_subdomains, t_end, nPOD * steps * dims), dtype=np.float32) \n",
    "\n",
    "for domain in range(evaluated_subdomains): \n",
    "    for i, dim in enumerate([0,2,1]):\n",
    "        for step in range(steps):\n",
    "            training_data[domain, :, steps*nPOD*i + step*nPOD : steps*nPOD*i + (step+1)*nPOD] = tmp_data[dim + domain][t_begin+step : t_end+step, :]\n",
    "\n",
    "# Adding data for leftmost and rightmost domain\n",
    "boundrary_conditions = []\n",
    "boundrary_conditions.append(tmp_data[0, steps-1:])\n",
    "boundrary_conditions.append(tmp_data[-1, steps-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e1e8bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[10009., 10014., 10019., 10024., 10029.],\n",
       "        [10010., 10015., 10020., 10025., 10030.],\n",
       "        [10011., 10016., 10021., 10026., 10031.],\n",
       "        ...,\n",
       "        [11006., 11011., 11016., 11021., 11026.],\n",
       "        [11007., 11012., 11017., 11022., 11027.],\n",
       "        [11008., 11013., 11018., 11023., 11028.]]),\n",
       " array([[40009., 40014., 40019., 40024., 40029.],\n",
       "        [40010., 40015., 40020., 40025., 40030.],\n",
       "        [40011., 40016., 40021., 40026., 40031.],\n",
       "        ...,\n",
       "        [41006., 41011., 41016., 41021., 41026.],\n",
       "        [41007., 41012., 41017., 41022., 41027.],\n",
       "        [41008., 41013., 41018., 41023., 41028.]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundrary_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ad3ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1000, 150)\n",
      "(2000, 150)\n"
     ]
    }
   ],
   "source": [
    "joined_train_data = training_data.reshape((training_data.shape[1]*training_data.shape[0], training_data.shape[2]))\n",
    "\n",
    "print(training_data.shape)\n",
    "print(joined_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d3288b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data[0,steps-1:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53575c8d",
   "metadata": {},
   "source": [
    "### Initializing GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c58a33c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making new generator and critic\n",
      "type and shape (nPOD by nTrain) of POD coeffs from csv file <class 'numpy.ndarray'> (2000, 150) float32\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"nsteps\" : steps,\n",
    "    \"ndims\" : dims * nPOD,\n",
    "    \"batch_size\" : 100,\n",
    "    \"batches\" : 20,\n",
    "    \"seed\" : 143,\n",
    "    \"epochs\" : 35000,\n",
    "    \"n_critic\" : 10,\n",
    "    \"gen_learning_rate\" : 5e-4,\n",
    "    \"disc_learning_rate\" : 5e-4,\n",
    "}\n",
    "\n",
    "gan = GAN(**kwargs)\n",
    "gan.setup()\n",
    "set_seed(gan.seed)\n",
    "assert gan.nsteps*gan.ndims*gan.batch_size*gan.batches - joined_train_data.shape[0]*joined_train_data.shape[1] == 0, \"Check inputs and data\"\n",
    "\n",
    "ndims_latent_input = gan.ndims\n",
    "joined_train_data = np.float32(joined_train_data)\n",
    "print('type and shape (nPOD by nTrain) of POD coeffs from csv file', type(joined_train_data), joined_train_data.shape, joined_train_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f54208e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "#gan.learn_hypersurface_from_POD_coeffs(joined_train_data)\n",
    "t_train = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a272b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 149), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.generator(np.zeros([1,10]))[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e90bb687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "tf.Tensor(\n",
      "[[[10000. 10005. 10010. 10015. 10020. 10001. 10006. 10011. 10016. 10021.\n",
      "   10002. 10007. 10012. 10017. 10022. 10003. 10008. 10013. 10018. 10023.\n",
      "   10004. 10009. 10014. 10019. 10024. 10005. 10010. 10015. 10020. 10025.\n",
      "   10006. 10011. 10016. 10021. 10026. 10007. 10012. 10017. 10022. 10027.\n",
      "   10008. 10013. 10018. 10023. 10028. 10009. 10014. 10019. 10024. 10029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028. 30009. 30014. 30019. 30024. 30029.\n",
      "   20000. 20005. 20010. 20015. 20020. 20001. 20006. 20011. 20016. 20021.\n",
      "   20002. 20007. 20012. 20017. 20022. 20003. 20008. 20013. 20018. 20023.\n",
      "   20004. 20009. 20014. 20019. 20024. 20005. 20010. 20015. 20020. 20025.\n",
      "   20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028.]]\n",
      "\n",
      " [[20000. 20005. 20010. 20015. 20020. 20001. 20006. 20011. 20016. 20021.\n",
      "   20002. 20007. 20012. 20017. 20022. 20003. 20008. 20013. 20018. 20023.\n",
      "   20004. 20009. 20014. 20019. 20024. 20005. 20010. 20015. 20020. 20025.\n",
      "   20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028. 20009. 20014. 20019. 20024. 20029.\n",
      "   40000. 40005. 40010. 40015. 40020. 40001. 40006. 40011. 40016. 40021.\n",
      "   40002. 40007. 40012. 40017. 40022. 40003. 40008. 40013. 40018. 40023.\n",
      "   40004. 40009. 40014. 40019. 40024. 40005. 40010. 40015. 40020. 40025.\n",
      "   40006. 40011. 40016. 40021. 40026. 40007. 40012. 40017. 40022. 40027.\n",
      "   40008. 40013. 40018. 40023. 40028. 40009. 40014. 40019. 40024. 40029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028.]]], shape=(2, 1, 145), dtype=float32)\n",
      "Time step: \t 1\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10001. 10006. 10011. 10016. 10021. 10002. 10007. 10012. 10017. 10022.\n",
      "   10003. 10008. 10013. 10018. 10023. 10004. 10009. 10014. 10019. 10024.\n",
      "   10005. 10010. 10015. 10020. 10025. 10006. 10011. 10016. 10021. 10026.\n",
      "   10007. 10012. 10017. 10022. 10027. 10008. 10013. 10018. 10023. 10028.\n",
      "   10009. 10014. 10019. 10024. 10029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "   30009. 30014. 30019. 30024. 30029. 20000. 20005. 20010. 20015. 20020.\n",
      "   20001. 20006. 20011. 20016. 20021. 20002. 20007. 20012. 20017. 20022.\n",
      "   20003. 20008. 20013. 20018. 20023. 20004. 20009. 20014. 20019. 20024.\n",
      "   20005. 20010. 20015. 20020. 20025. 20006. 20011. 20016. 20021. 20026.\n",
      "   20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20001. 20006. 20011. 20016. 20021. 20002. 20007. 20012. 20017. 20022.\n",
      "   20003. 20008. 20013. 20018. 20023. 20004. 20009. 20014. 20019. 20024.\n",
      "   20005. 20010. 20015. 20020. 20025. 20006. 20011. 20016. 20021. 20026.\n",
      "   20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "   20009. 20014. 20019. 20024. 20029. 40000. 40005. 40010. 40015. 40020.\n",
      "   40001. 40006. 40011. 40016. 40021. 40002. 40007. 40012. 40017. 40022.\n",
      "   40003. 40008. 40013. 40018. 40023. 40004. 40009. 40014. 40019. 40024.\n",
      "   40005. 40010. 40015. 40020. 40025. 40006. 40011. 40016. 40021. 40026.\n",
      "   40007. 40012. 40017. 40022. 40027. 40008. 40013. 40018. 40023. 40028.\n",
      "   40009. 40014. 40019. 40024. 40029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "       0.     0.     0.     0.     0.]]]\n",
      "Time step: \t 2\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10002. 10007. 10012. 10017. 10022. 10003. 10008. 10013. 10018. 10023.\n",
      "   10004. 10009. 10014. 10019. 10024. 10005. 10010. 10015. 10020. 10025.\n",
      "   10006. 10011. 10016. 10021. 10026. 10007. 10012. 10017. 10022. 10027.\n",
      "   10008. 10013. 10018. 10023. 10028. 10009. 10014. 10019. 10024. 10029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028. 30009. 30014. 30019. 30024. 30029.\n",
      "   20000. 20005. 20010. 20015. 20020. 20001. 20006. 20011. 20016. 20021.\n",
      "   20002. 20007. 20012. 20017. 20022. 20003. 20008. 20013. 20018. 20023.\n",
      "   20004. 20009. 20014. 20019. 20024. 20005. 20010. 20015. 20020. 20025.\n",
      "   20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20002. 20007. 20012. 20017. 20022. 20003. 20008. 20013. 20018. 20023.\n",
      "   20004. 20009. 20014. 20019. 20024. 20005. 20010. 20015. 20020. 20025.\n",
      "   20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028. 20009. 20014. 20019. 20024. 20029.\n",
      "   40000. 40005. 40010. 40015. 40020. 40001. 40006. 40011. 40016. 40021.\n",
      "   40002. 40007. 40012. 40017. 40022. 40003. 40008. 40013. 40018. 40023.\n",
      "   40004. 40009. 40014. 40019. 40024. 40005. 40010. 40015. 40020. 40025.\n",
      "   40006. 40011. 40016. 40021. 40026. 40007. 40012. 40017. 40022. 40027.\n",
      "   40008. 40013. 40018. 40023. 40028. 40009. 40014. 40019. 40024. 40029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]]\n",
      "Time step: \t 3\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10003. 10008. 10013. 10018. 10023. 10004. 10009. 10014. 10019. 10024.\n",
      "   10005. 10010. 10015. 10020. 10025. 10006. 10011. 10016. 10021. 10026.\n",
      "   10007. 10012. 10017. 10022. 10027. 10008. 10013. 10018. 10023. 10028.\n",
      "   10009. 10014. 10019. 10024. 10029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "   30009. 30014. 30019. 30024. 30029. 20000. 20005. 20010. 20015. 20020.\n",
      "   20001. 20006. 20011. 20016. 20021. 20002. 20007. 20012. 20017. 20022.\n",
      "   20003. 20008. 20013. 20018. 20023. 20004. 20009. 20014. 20019. 20024.\n",
      "   20005. 20010. 20015. 20020. 20025. 20006. 20011. 20016. 20021. 20026.\n",
      "   20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20003. 20008. 20013. 20018. 20023. 20004. 20009. 20014. 20019. 20024.\n",
      "   20005. 20010. 20015. 20020. 20025. 20006. 20011. 20016. 20021. 20026.\n",
      "   20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "   20009. 20014. 20019. 20024. 20029. 40000. 40005. 40010. 40015. 40020.\n",
      "   40001. 40006. 40011. 40016. 40021. 40002. 40007. 40012. 40017. 40022.\n",
      "   40003. 40008. 40013. 40018. 40023. 40004. 40009. 40014. 40019. 40024.\n",
      "   40005. 40010. 40015. 40020. 40025. 40006. 40011. 40016. 40021. 40026.\n",
      "   40007. 40012. 40017. 40022. 40027. 40008. 40013. 40018. 40023. 40028.\n",
      "   40009. 40014. 40019. 40024. 40029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]]\n",
      "Time step: \t 4\n",
      "Optimizer epoch: \t 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10004. 10009. 10014. 10019. 10024. 10005. 10010. 10015. 10020. 10025.\n",
      "   10006. 10011. 10016. 10021. 10026. 10007. 10012. 10017. 10022. 10027.\n",
      "   10008. 10013. 10018. 10023. 10028. 10009. 10014. 10019. 10024. 10029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028. 30009. 30014. 30019. 30024. 30029.\n",
      "   20000. 20005. 20010. 20015. 20020. 20001. 20006. 20011. 20016. 20021.\n",
      "   20002. 20007. 20012. 20017. 20022. 20003. 20008. 20013. 20018. 20023.\n",
      "   20004. 20009. 20014. 20019. 20024. 20005. 20010. 20015. 20020. 20025.\n",
      "   20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20004. 20009. 20014. 20019. 20024. 20005. 20010. 20015. 20020. 20025.\n",
      "   20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028. 20009. 20014. 20019. 20024. 20029.\n",
      "   40000. 40005. 40010. 40015. 40020. 40001. 40006. 40011. 40016. 40021.\n",
      "   40002. 40007. 40012. 40017. 40022. 40003. 40008. 40013. 40018. 40023.\n",
      "   40004. 40009. 40014. 40019. 40024. 40005. 40010. 40015. 40020. 40025.\n",
      "   40006. 40011. 40016. 40021. 40026. 40007. 40012. 40017. 40022. 40027.\n",
      "   40008. 40013. 40018. 40023. 40028. 40009. 40014. 40019. 40024. 40029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]]\n",
      "Time step: \t 5\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10005. 10010. 10015. 10020. 10025. 10006. 10011. 10016. 10021. 10026.\n",
      "   10007. 10012. 10017. 10022. 10027. 10008. 10013. 10018. 10023. 10028.\n",
      "   10009. 10014. 10019. 10024. 10029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "   30009. 30014. 30019. 30024. 30029. 20000. 20005. 20010. 20015. 20020.\n",
      "   20001. 20006. 20011. 20016. 20021. 20002. 20007. 20012. 20017. 20022.\n",
      "   20003. 20008. 20013. 20018. 20023. 20004. 20009. 20014. 20019. 20024.\n",
      "   20005. 20010. 20015. 20020. 20025. 20006. 20011. 20016. 20021. 20026.\n",
      "   20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20005. 20010. 20015. 20020. 20025. 20006. 20011. 20016. 20021. 20026.\n",
      "   20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "   20009. 20014. 20019. 20024. 20029. 40000. 40005. 40010. 40015. 40020.\n",
      "   40001. 40006. 40011. 40016. 40021. 40002. 40007. 40012. 40017. 40022.\n",
      "   40003. 40008. 40013. 40018. 40023. 40004. 40009. 40014. 40019. 40024.\n",
      "   40005. 40010. 40015. 40020. 40025. 40006. 40011. 40016. 40021. 40026.\n",
      "   40007. 40012. 40017. 40022. 40027. 40008. 40013. 40018. 40023. 40028.\n",
      "   40009. 40014. 40019. 40024. 40029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]]\n",
      "Time step: \t 6\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10006. 10011. 10016. 10021. 10026. 10007. 10012. 10017. 10022. 10027.\n",
      "   10008. 10013. 10018. 10023. 10028. 10009. 10014. 10019. 10024. 10029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028. 30009. 30014. 30019. 30024. 30029.\n",
      "   20000. 20005. 20010. 20015. 20020. 20001. 20006. 20011. 20016. 20021.\n",
      "   20002. 20007. 20012. 20017. 20022. 20003. 20008. 20013. 20018. 20023.\n",
      "   20004. 20009. 20014. 20019. 20024. 20005. 20010. 20015. 20020. 20025.\n",
      "   20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028. 20009. 20014. 20019. 20024. 20029.\n",
      "   40000. 40005. 40010. 40015. 40020. 40001. 40006. 40011. 40016. 40021.\n",
      "   40002. 40007. 40012. 40017. 40022. 40003. 40008. 40013. 40018. 40023.\n",
      "   40004. 40009. 40014. 40019. 40024. 40005. 40010. 40015. 40020. 40025.\n",
      "   40006. 40011. 40016. 40021. 40026. 40007. 40012. 40017. 40022. 40027.\n",
      "   40008. 40013. 40018. 40023. 40028. 40009. 40014. 40019. 40024. 40029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]]\n",
      "Time step: \t 7\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10007. 10012. 10017. 10022. 10027. 10008. 10013. 10018. 10023. 10028.\n",
      "   10009. 10014. 10019. 10024. 10029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "   30009. 30014. 30019. 30024. 30029. 20000. 20005. 20010. 20015. 20020.\n",
      "   20001. 20006. 20011. 20016. 20021. 20002. 20007. 20012. 20017. 20022.\n",
      "   20003. 20008. 20013. 20018. 20023. 20004. 20009. 20014. 20019. 20024.\n",
      "   20005. 20010. 20015. 20020. 20025. 20006. 20011. 20016. 20021. 20026.\n",
      "   20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "   20009. 20014. 20019. 20024. 20029. 40000. 40005. 40010. 40015. 40020.\n",
      "   40001. 40006. 40011. 40016. 40021. 40002. 40007. 40012. 40017. 40022.\n",
      "   40003. 40008. 40013. 40018. 40023. 40004. 40009. 40014. 40019. 40024.\n",
      "   40005. 40010. 40015. 40020. 40025. 40006. 40011. 40016. 40021. 40026.\n",
      "   40007. 40012. 40017. 40022. 40027. 40008. 40013. 40018. 40023. 40028.\n",
      "   40009. 40014. 40019. 40024. 40029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]]\n",
      "Time step: \t 8\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10008. 10013. 10018. 10023. 10028. 10009. 10014. 10019. 10024. 10029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028. 30009. 30014. 30019. 30024. 30029.\n",
      "   20000. 20005. 20010. 20015. 20020. 20001. 20006. 20011. 20016. 20021.\n",
      "   20002. 20007. 20012. 20017. 20022. 20003. 20008. 20013. 20018. 20023.\n",
      "   20004. 20009. 20014. 20019. 20024. 20005. 20010. 20015. 20020. 20025.\n",
      "   20006. 20011. 20016. 20021. 20026. 20007. 20012. 20017. 20022. 20027.\n",
      "   20008. 20013. 20018. 20023. 20028.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20008. 20013. 20018. 20023. 20028. 20009. 20014. 20019. 20024. 20029.\n",
      "   40000. 40005. 40010. 40015. 40020. 40001. 40006. 40011. 40016. 40021.\n",
      "   40002. 40007. 40012. 40017. 40022. 40003. 40008. 40013. 40018. 40023.\n",
      "   40004. 40009. 40014. 40019. 40024. 40005. 40010. 40015. 40020. 40025.\n",
      "   40006. 40011. 40016. 40021. 40026. 40007. 40012. 40017. 40022. 40027.\n",
      "   40008. 40013. 40018. 40023. 40028. 40009. 40014. 40019. 40024. 40029.\n",
      "   30000. 30005. 30010. 30015. 30020. 30001. 30006. 30011. 30016. 30021.\n",
      "   30002. 30007. 30012. 30017. 30022. 30003. 30008. 30013. 30018. 30023.\n",
      "   30004. 30009. 30014. 30019. 30024. 30005. 30010. 30015. 30020. 30025.\n",
      "   30006. 30011. 30016. 30021. 30026. 30007. 30012. 30017. 30022. 30027.\n",
      "   30008. 30013. 30018. 30023. 30028.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]]\n",
      "Time step: \t 9\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "Optimizer epoch: \t 0\n",
      "[[[10009. 10014. 10019. 10024. 10029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "   30009. 30014. 30019. 30024. 30029. 20000. 20005. 20010. 20015. 20020.\n",
      "   20001. 20006. 20011. 20016. 20021. 20002. 20007. 20012. 20017. 20022.\n",
      "   20003. 20008. 20013. 20018. 20023. 20004. 20009. 20014. 20019. 20024.\n",
      "   20005. 20010. 20015. 20020. 20025. 20006. 20011. 20016. 20021. 20026.\n",
      "   20007. 20012. 20017. 20022. 20027. 20008. 20013. 20018. 20023. 20028.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]\n",
      "\n",
      " [[20009. 20014. 20019. 20024. 20029. 40000. 40005. 40010. 40015. 40020.\n",
      "   40001. 40006. 40011. 40016. 40021. 40002. 40007. 40012. 40017. 40022.\n",
      "   40003. 40008. 40013. 40018. 40023. 40004. 40009. 40014. 40019. 40024.\n",
      "   40005. 40010. 40015. 40020. 40025. 40006. 40011. 40016. 40021. 40026.\n",
      "   40007. 40012. 40017. 40022. 40027. 40008. 40013. 40018. 40023. 40028.\n",
      "   40009. 40014. 40019. 40024. 40029. 30000. 30005. 30010. 30015. 30020.\n",
      "   30001. 30006. 30011. 30016. 30021. 30002. 30007. 30012. 30017. 30022.\n",
      "   30003. 30008. 30013. 30018. 30023. 30004. 30009. 30014. 30019. 30024.\n",
      "   30005. 30010. 30015. 30020. 30025. 30006. 30011. 30016. 30021. 30026.\n",
      "   30007. 30012. 30017. 30022. 30027. 30008. 30013. 30018. 30023. 30028.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "       0.     0.     0.     0.     0.]]]\n"
     ]
    }
   ],
   "source": [
    "kwargs_opt = {\n",
    "    \"start_from\" : 0,\n",
    "    \"nPOD\" : 5,\n",
    "    \"nLatent\" : 10,\n",
    "    \"npredictions\" : 10,\n",
    "    \"optimizer_epochs\" : 1,\n",
    "    \"gan\" : gan,\n",
    "    \"bounds\" : 1e5,\n",
    "    \"cycles\" : 3\n",
    "}\n",
    "\n",
    "optimizer = Optimize(**kwargs_opt)\n",
    "flds = optimizer.predictDD(training_data, tf.convert_to_tensor(np.array(boundrary_conditions, dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaf4b0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 39, 5), dtype=float32, numpy=\n",
       "array([[[10000., 10005., 10010., 10015., 10020.],\n",
       "        [10001., 10006., 10011., 10016., 10021.],\n",
       "        [10002., 10007., 10012., 10017., 10022.],\n",
       "        [10003., 10008., 10013., 10018., 10023.],\n",
       "        [10004., 10009., 10014., 10019., 10024.],\n",
       "        [10005., 10010., 10015., 10020., 10025.],\n",
       "        [10006., 10011., 10016., 10021., 10026.],\n",
       "        [10007., 10012., 10017., 10022., 10027.],\n",
       "        [10008., 10013., 10018., 10023., 10028.],\n",
       "        [10009., 10014., 10019., 10024., 10029.],\n",
       "        [30000., 30005., 30010., 30015., 30020.],\n",
       "        [30001., 30006., 30011., 30016., 30021.],\n",
       "        [30002., 30007., 30012., 30017., 30022.],\n",
       "        [30003., 30008., 30013., 30018., 30023.],\n",
       "        [30004., 30009., 30014., 30019., 30024.],\n",
       "        [30005., 30010., 30015., 30020., 30025.],\n",
       "        [30006., 30011., 30016., 30021., 30026.],\n",
       "        [30007., 30012., 30017., 30022., 30027.],\n",
       "        [30008., 30013., 30018., 30023., 30028.],\n",
       "        [30009., 30014., 30019., 30024., 30029.],\n",
       "        [20000., 20005., 20010., 20015., 20020.],\n",
       "        [20001., 20006., 20011., 20016., 20021.],\n",
       "        [20002., 20007., 20012., 20017., 20022.],\n",
       "        [20003., 20008., 20013., 20018., 20023.],\n",
       "        [20004., 20009., 20014., 20019., 20024.],\n",
       "        [20005., 20010., 20015., 20020., 20025.],\n",
       "        [20006., 20011., 20016., 20021., 20026.],\n",
       "        [20007., 20012., 20017., 20022., 20027.],\n",
       "        [20008., 20013., 20018., 20023., 20028.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.]],\n",
       "\n",
       "       [[20000., 20005., 20010., 20015., 20020.],\n",
       "        [20001., 20006., 20011., 20016., 20021.],\n",
       "        [20002., 20007., 20012., 20017., 20022.],\n",
       "        [20003., 20008., 20013., 20018., 20023.],\n",
       "        [20004., 20009., 20014., 20019., 20024.],\n",
       "        [20005., 20010., 20015., 20020., 20025.],\n",
       "        [20006., 20011., 20016., 20021., 20026.],\n",
       "        [20007., 20012., 20017., 20022., 20027.],\n",
       "        [20008., 20013., 20018., 20023., 20028.],\n",
       "        [20009., 20014., 20019., 20024., 20029.],\n",
       "        [40000., 40005., 40010., 40015., 40020.],\n",
       "        [40001., 40006., 40011., 40016., 40021.],\n",
       "        [40002., 40007., 40012., 40017., 40022.],\n",
       "        [40003., 40008., 40013., 40018., 40023.],\n",
       "        [40004., 40009., 40014., 40019., 40024.],\n",
       "        [40005., 40010., 40015., 40020., 40025.],\n",
       "        [40006., 40011., 40016., 40021., 40026.],\n",
       "        [40007., 40012., 40017., 40022., 40027.],\n",
       "        [40008., 40013., 40018., 40023., 40028.],\n",
       "        [40009., 40014., 40019., 40024., 40029.],\n",
       "        [30000., 30005., 30010., 30015., 30020.],\n",
       "        [30001., 30006., 30011., 30016., 30021.],\n",
       "        [30002., 30007., 30012., 30017., 30022.],\n",
       "        [30003., 30008., 30013., 30018., 30023.],\n",
       "        [30004., 30009., 30014., 30019., 30024.],\n",
       "        [30005., 30010., 30015., 30020., 30025.],\n",
       "        [30006., 30011., 30016., 30021., 30026.],\n",
       "        [30007., 30012., 30017., 30022., 30027.],\n",
       "        [30008., 30013., 30018., 30023., 30028.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0.,     0.,     0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1748eeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 39, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcab6316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e444587f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10010., 10015., 10020., 10025., 10030.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(boundrary_conditions)[0,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9792313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 135)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1][optimizer.start_from,\n",
    "            :(optimizer.gan.nsteps-1)*optimizer.nPOD * 3 \n",
    "            ].reshape(1, (optimizer.gan.nsteps - 1) * optimizer.nPOD* 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b372c5c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GAN' object has no attribute 'npredictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2e385ea0bce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GAN' object has no attribute 'npredictions'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=[20,10])\n",
    "ax.plot(csv_data[:gan.npredictions, :])\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=[20,10])\n",
    "ax.plot(csv_data[:, :])\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=[20,10])\n",
    "ax.plot(csv_data[:gan.npredictions, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=[20,10])\n",
    "ax.plot(flds[-10:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/reconstructed/velocity_field.npy', np.reshape((basis[:,:gan.ndims] @ scaling.inverse_transform((flds)).T), [1,2,221,42,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0274f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = np.load('../data/processed/pod_basis_field_Velocity.npy')\n",
    "\n",
    "\n",
    "tmp_data2 = np.zeros_like(csv_data)\n",
    "for i in range(subdomains):\n",
    "    scales.append(sklearn.preprocessing.MinMaxScaler(feature_range=[-1,1]))\n",
    "    csv_data2[i] = scales[i].fit_transform(csv_data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125cb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling.inverse_transform(flds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35622f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = np.load('../data/processed/pod_basis_field_Velocity.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeeafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(8000):\n",
    "    a.append(np.max(basis[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a678a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(8000),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1364d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(basis[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boundrary_conditions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundrary_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012599b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9f4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a423526d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f33014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07460300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2757e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54000da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64249366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b0259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
